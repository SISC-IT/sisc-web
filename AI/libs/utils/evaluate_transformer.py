import os
import sys
import pickle
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€ (ë²„ì „ ì°¨ì´ ê²½ê³  ë“±)
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ì„¤ì • ë° ê²½ë¡œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_this_file = os.path.abspath(__file__)
project_root = os.path.dirname(os.path.dirname(_this_file))           # .../transformer
repo_root    = os.path.dirname(project_root)         # .../AI

if project_root not in sys.path: sys.path.append(project_root)
if repo_root not in sys.path: sys.path.append(repo_root)

from modules.models import build_transformer_classifier
from modules.features import FEATURES, build_features
from AI.transformer.training.training_transformer import (
    _fetch_db_ohlcv_for_tickers, 
    load_all_tickers_from_db,
    _label_by_future_return,
    _build_sequences,
    _align_labels
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  í‰ê°€ ì„¤ì • (CONFIG)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG = {
    "seq_len": 128,
    "pred_h": 7,       
    "hold_thr": 0.003, 
    
    # ê²½ë¡œ í˜¸í™˜ì„±ì„ ìœ„í•´ os.path.join ì‚¬ìš©
    "weights_path": os.path.join(project_root, "weights", "initial.weights.h5"),
    "scaler_path": os.path.join(project_root, "scaler", "scaler.pkl"),
    
    # í‰ê°€í•˜ê³  ì‹¶ì€ "ê²°ê³¼"ì˜ ê¸°ê°„
    "eval_start_date": "2025-01-01", 
    "eval_end_date": "2025-10-31",
    
    # Noneì´ë©´ ì „ì²´ ì¢…ëª©, ë¦¬ìŠ¤íŠ¸ë©´ íŠ¹ì • ì¢…ëª©ë§Œ
    "test_tickers": None, 
    "batch_size": 512
}

def evaluate_model():
    print(f"\n[EVAL] ğŸš€ Transformer ëª¨ë¸ í‰ê°€ ì‹œì‘")
    print(f"       í‰ê°€ ëŒ€ìƒ ê¸°ê°„: {CONFIG['eval_start_date']} ~ {CONFIG['eval_end_date']}")
    
    # 1. íŒŒì¼ í™•ì¸
    if not os.path.exists(CONFIG['weights_path']) or not os.path.exists(CONFIG['scaler_path']):
        print(f"[ERR] âŒ í•„ìˆ˜ íŒŒì¼ ëˆ„ë½.\n      {CONFIG['weights_path']}\n      ë¨¼ì € í•™ìŠµ(train_transformer.py)ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    # 2. ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    try:
        with open(CONFIG['scaler_path'], "rb") as f:
            scaler = pickle.load(f)
        print("[EVAL] âœ… ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"[ERR] ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        return

    # 3. í‹°ì»¤ ë¡œë“œ
    if CONFIG['test_tickers']:
        tickers = CONFIG['test_tickers']
    else:
        print("[EVAL] DBì—ì„œ ì „ì²´ í‹°ì»¤ ëª©ë¡ ì¡°íšŒ ì¤‘...")
        tickers = load_all_tickers_from_db(verbose=False)
    
    # 4. ë°ì´í„° ìˆ˜ì§‘ (Warm-up ê¸°ê°„ í¬í•¨í•˜ì—¬ ë„‰ë„‰í•˜ê²Œ ì¡°íšŒ)
    fetch_start = pd.to_datetime(CONFIG['eval_start_date']) - pd.Timedelta(days=365)
    fetch_start_str = fetch_start.strftime("%Y-%m-%d")
    
    print(f"[EVAL] ë°ì´í„° ìˆ˜ì§‘ ì¤‘... (ì¡°íšŒ ì‹œì‘ì¼: {fetch_start_str}, ëŒ€ìƒ: {len(tickers)}ê°œ)")
    
    raw_df = _fetch_db_ohlcv_for_tickers(tickers, fetch_start_str, CONFIG['eval_end_date'])
    
    if raw_df.empty:
        print("[ERR] âŒ í•´ë‹¹ ê¸°ê°„ì˜ ë°ì´í„°ê°€ DBì— ì „í˜€ ì—†ìŠµë‹ˆë‹¤. DB ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"[EVAL] ìˆ˜ì§‘ëœ ë°ì´í„° í–‰ ìˆ˜: {len(raw_df)} rows")

    # 5. ì „ì²˜ë¦¬
    model_feats = [f for f in FEATURES if f != "CLOSE_RAW"]
    X_all, y_all = [], []
    returns_all = [] 

    print("[EVAL] í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ë° ì‹œí€€ìŠ¤ ë³€í™˜ ì¤‘...")
    
    count_skipped = 0
    count_ok = 0

    for t, g in raw_df.groupby("ticker"):
        g = g.rename(columns={'ts_local': 'date'}).set_index('date')
        g = g.sort_index()
        
        # í”¼ì²˜ ìƒì„±
        feats = build_features(g)
        
        # ë¼ë²¨ ìƒì„±
        labels = _label_by_future_return(feats["CLOSE_RAW"], CONFIG['pred_h'], CONFIG['hold_thr'])
        
        # ìˆ˜ìµë¥  (ë‹¨ìˆœí™”: ì¢…ê°€ ëŒ€ ì¢…ê°€)
        future_ret = (feats["CLOSE_RAW"].shift(-CONFIG['pred_h']) / feats["CLOSE_RAW"]) - 1.0
        
        # ìœ íš¨ ë°ì´í„° í•„í„°ë§
        valid = feats.notna().all(axis=1) & labels.notna() & future_ret.notna()
        feats = feats[valid]
        labels = labels[valid]
        future_ret = future_ret[valid]
        
        if len(feats) < CONFIG['seq_len']:
            count_skipped += 1
            continue

        # ì‹œí€€ìŠ¤ ìƒì„±
        X_seq = _build_sequences(feats, model_feats, CONFIG['seq_len'])
        y_seq = _align_labels(feats, labels, CONFIG['seq_len'])
        r_seq = _align_labels(feats, future_ret, CONFIG['seq_len'])
        
        # ë‚ ì§œ ì¸ë±ìŠ¤ë„ ê°™ì´ ì •ë ¬í•´ì„œ ê°€ì ¸ì˜´
        dates_seq = feats.index[CONFIG['seq_len']-1:]

        # ê¸¸ì´ ë§ì¶”ê¸°
        min_len = min(len(X_seq), len(y_seq), len(r_seq), len(dates_seq))
        X_seq = X_seq[:min_len]
        y_seq = y_seq[:min_len]
        r_seq = r_seq[:min_len]
        dates_seq = dates_seq[:min_len]
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # [ìˆ˜ì •] ì¸ë±ìŠ¤ ì •ê·œí™” ë° íƒ€ì„ì¡´ ì²˜ë¦¬ (Robust Fix)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 1) MultiIndex ì²˜ë¦¬ (Date, Ticker)
        if isinstance(dates_seq, pd.MultiIndex):
            dates_seq = dates_seq.get_level_values(0)
        
        # 2) íŠœí”Œ í˜•íƒœì˜ ì¼ë°˜ Index ì²˜ë¦¬ (dtype=object)
        #    ì˜ˆ: Index([(Timestamp(...), 'KRW-BTC'), ...], dtype='object')
        elif dates_seq.dtype == 'object' and len(dates_seq) > 0 and isinstance(dates_seq[0], tuple):
            dates_seq = pd.Index([x[0] for x in dates_seq])

        # 3) DatetimeIndexë¡œ í™•ì‹¤í•˜ê²Œ ë³€í™˜
        dates_seq = pd.to_datetime(dates_seq)

        # 4) íƒ€ì„ì¡´(Timezone) í˜¸í™˜ì„± ì²˜ë¦¬
        target_start = pd.to_datetime(CONFIG['eval_start_date'])
        target_end = pd.to_datetime(CONFIG['eval_end_date']) + pd.Timedelta(days=1)

        if dates_seq.tz is not None:
            # ë°ì´í„°ê°€ TZ-awareë¼ë©´, ë¹„êµ ë‚ ì§œë„ í•´ë‹¹ TZë¡œ ë³€í™˜
            if target_start.tz is None:
                target_start = target_start.tz_localize(dates_seq.tz)
            else:
                target_start = target_start.tz_convert(dates_seq.tz)
                
            if target_end.tz is None:
                target_end = target_end.tz_localize(dates_seq.tz)
            else:
                target_end = target_end.tz_convert(dates_seq.tz)
        else:
            # ë°ì´í„°ê°€ Naiveë¼ë©´, ë¹„êµ ë‚ ì§œë„ Naiveë¡œ ìœ ì§€ (í˜¹ì‹œ Awareë¼ë©´ ì œê±°)
            if target_start.tz is not None:
                target_start = target_start.tz_localize(None)
            if target_end.tz is not None:
                target_end = target_end.tz_localize(None)

        # â˜… í‰ê°€ ê¸°ê°„ í•„í„°ë§
        eval_mask = (dates_seq >= target_start) & (dates_seq <= target_end)
        
        if eval_mask.sum() == 0:
            count_skipped += 1
            continue

        X_all.append(X_seq[eval_mask])
        y_all.append(y_seq[eval_mask])
        returns_all.append(r_seq[eval_mask])
        count_ok += 1

    if not X_all:
        print(f"\n[ERR] âŒ ìœ íš¨ ì‹œí€€ìŠ¤ ìƒì„± ì‹¤íŒ¨.")
        print(f"      - ì´ ì¢…ëª© ìˆ˜: {len(tickers)}")
        print(f"      - ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ìŠ¤í‚µëœ ì¢…ëª©: {count_skipped}")
        return

    X = np.concatenate(X_all, axis=0)
    y = np.concatenate(y_all, axis=0).astype(int)
    r = np.concatenate(returns_all, axis=0)

    print(f"[EVAL] ìƒì„±ëœ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(X)}ê°œ (ì‚¬ìš© ì¢…ëª©: {count_ok}ê°œ)")

    # 6. ìŠ¤ì¼€ì¼ë§ & ì˜ˆì¸¡
    n, s, f = X.shape
    X_reshaped = X.reshape(-1, f)
    X_scaled = scaler.transform(X_reshaped).reshape(n, s, f)

    print("[EVAL] ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
    model = build_transformer_classifier(CONFIG['seq_len'], f)
    model.load_weights(CONFIG['weights_path'])
    
    y_pred_probs = model.predict(X_scaled, batch_size=CONFIG['batch_size'], verbose=1)
    y_pred = np.argmax(y_pred_probs, axis=1)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ê²°ê³¼ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "="*60)
    print("ğŸ“¢ [RESULT] Transformer ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸")
    print("="*60)

    acc = accuracy_score(y, y_pred)
    print(f"\n1ï¸âƒ£  ì •í™•ë„ (Accuracy): {acc*100:.2f}%")
    print(classification_report(y, y_pred, target_names=["BUY", "HOLD", "SELL"]))

    print("\n2ï¸âƒ£  í˜¼ë™ í–‰ë ¬ (Confusion Matrix):")
    cm = confusion_matrix(y, y_pred)
    print(f"      Pred: BUY  HOLD  SELL")
    print(f"Actual BUY  {cm[0]}")
    print(f"Actual HOLD {cm[1]}")
    print(f"Actual SELL {cm[2]}")
    
    print("\n3ï¸âƒ£  ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜ (ë‹¨ìˆœ ê°€ì •)")
    buy_signals = (y_pred == 0)
    avg_ret_buy = np.mean(r[buy_signals]) if np.sum(buy_signals) > 0 else 0.0
    mkt_avg = np.mean(r)
    
    real_wins = r[buy_signals] > CONFIG['hold_thr']
    win_rate = np.mean(real_wins) if len(real_wins) > 0 else 0.0

    print(f"ì´ ê±°ë˜ ê¸°íšŒ: {len(r)}")
    print(f"BUY ì‹ í˜¸ ìˆ˜ : {np.sum(buy_signals)}")
    print("-" * 30)
    print(f"BUY í‰ê·  ìˆ˜ìµë¥  : {avg_ret_buy*100:.4f}%  (vs ì‹œì¥í‰ê·  {mkt_avg*100:.4f}%)")
    print(f"BUY ì ì¤‘ë¥       : {win_rate*100:.2f}%")
    print("-" * 30)

if __name__ == "__main__":
    evaluate_model()