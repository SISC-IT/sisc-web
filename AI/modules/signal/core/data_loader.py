# AI/modules/signal/core/data_loader.py
"""
[ë°ì´í„° ë¡œë” - Multi-Horizon Version]
- 1, 3, 5, 7ì¼ ë’¤ì˜ ë“±ë½ì„ í•œ ë²ˆì— ëª¨ë‘ ë¼ë²¨ë§í•©ë‹ˆë‹¤.
- ì •ë‹µ(y)ì˜ ëª¨ì–‘ì´ (N,)ì—ì„œ (N, 4)ë¡œ ë°”ë€ë‹ˆë‹¤.
"""

import numpy as np
import pandas as pd
from typing import Tuple, Dict
from sklearn.preprocessing import MinMaxScaler
from tqdm import tqdm

import sys
import os

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../../.."))
if project_root not in sys.path:
    sys.path.append(project_root)

from AI.libs.database.connection import get_db_conn
from AI.modules.signal.core.features import add_technical_indicators, add_multi_timeframe_features

class DataLoader:
    def __init__(self, db_name="db", lookback=60):
        self.db_name = db_name
        self.lookback = lookback
        self.scaler = MinMaxScaler()
        
        self.ticker_to_id: Dict[str, int] = {}
        self.sector_to_id: Dict[str, int] = {}
        self.ticker_sector_map: Dict[str, int] = {}
        
        self._load_metadata()

    def _load_metadata(self):
        conn = get_db_conn(self.db_name)
        cursor = conn.cursor()
        try:
            query = "SELECT ticker, COALESCE(sector, 'Unknown') FROM public.stock_info"
            cursor.execute(query)
            rows = cursor.fetchall()
            unique_sectors = sorted(list(set([row[1] for row in rows])))
            self.sector_to_id = {sec: i for i, sec in enumerate(unique_sectors)}
            self.ticker_sector_map = {row[0]: self.sector_to_id[row[1]] for row in rows}
            self.ticker_to_id = {row[0]: i for i, row in enumerate(rows)}
            print(f"[DataLoader] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.ticker_to_id)}ê°œ ì¢…ëª©")
        except Exception as e:
            print(f"[DataLoader] ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        finally:
            if cursor: cursor.close()
            if conn: conn.close()

    def load_data_from_db(self, start_date="2018-01-01") -> pd.DataFrame:
        conn = get_db_conn(self.db_name)
        query = f"""
            SELECT date, ticker, open, high, low, close, volume, adjusted_close
            FROM public.price_data
            WHERE date >= '{start_date}'
            ORDER BY ticker, date ASC
        """
        df = pd.read_sql(query, conn)
        conn.close()
        df['date'] = pd.to_datetime(df['date'])
        return df

    def create_dataset(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, Dict]:
        X_ts_list = []
        X_ticker_list = []
        X_sector_list = []
        y_class_list = [] # ì´ì œ ì—¬ê¸°ê°€ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸ê°€ ë¨
        y_reg_list = []   
        
        # -----------------------------------------------------------
        # [ì„¤ì •] Multi-Horizon (1, 3, 5, 7ì¼ ë’¤ ì˜ˆì¸¡)
        # -----------------------------------------------------------
        HORIZONS = [1, 3, 5, 7]
        max_horizon = max(HORIZONS)
        print(f"ğŸ¯ ì˜ˆì¸¡ ëª©í‘œ: {HORIZONS}ì¼ ë’¤ì˜ ë“±ë½ì„ ë™ì‹œ ì˜ˆì¸¡")

        tickers = df['ticker'].unique()
        print(f"[DataLoader] {len(tickers)}ê°œ ì¢…ëª©ì— ëŒ€í•´ Feature Engineering ì‹œì‘...")

        processed_dfs = []
        for ticker in tqdm(tickers, desc="Adding Indicators"):
            sub_df = df[df['ticker'] == ticker].copy().sort_values('date')
            
            if len(sub_df) < 200: continue
            if sub_df['close'].std() == 0: continue # ì¢€ë¹„ ë°ì´í„° ì œê±°

            sub_df = add_technical_indicators(sub_df)
            try:
                sub_df = add_multi_timeframe_features(sub_df)
            except Exception:
                continue
            
            processed_dfs.append(sub_df)
            
        if not processed_dfs: raise ValueError("[Error] ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        full_df = pd.concat(processed_dfs)
        
        full_df['raw_close'] = full_df['close']
        
        feature_cols = [
            'log_return', 
            'open_ratio', 'high_ratio', 'low_ratio', 
            'vol_change',
            'ma5_ratio', 'ma20_ratio', 'ma60_ratio', 
            'rsi', 
            'macd_ratio', 
            'bb_position',
            'week_ma20_ratio', 'week_rsi', 'week_bb_pos', 'week_vol_change',
            'month_ma12_ratio', 'month_rsi'
        ]
        
        available_cols = [c for c in feature_cols if c in full_df.columns]
        full_df = full_df.dropna(subset=available_cols)
        
        print(f">> ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì¤‘... (Features: {len(available_cols)}ê°œ)")
        full_df[available_cols] = self.scaler.fit_transform(full_df[available_cols])

        print(">> ì‹œí€€ìŠ¤ ë° ë¼ë²¨ ìƒì„± ì¤‘...")
        
        debug_printed = False
        
        for ticker in tqdm(full_df['ticker'].unique(), desc="Sequencing"):
            sub_df = full_df[full_df['ticker'] == ticker]
            # ë°ì´í„°ê°€ (lookback + ê°€ì¥ ë¨¼ ë¯¸ë˜) ë³´ë‹¤ ë§ì•„ì•¼ í•¨
            if len(sub_df) <= self.lookback + max_horizon: continue

            t_id = self.ticker_to_id.get(ticker, 0)
            s_id = self.ticker_sector_map.get(ticker, 0)

            values = sub_df[available_cols].values
            raw_closes = sub_df['raw_close'].values 
            
            if not debug_printed:
                print(f"\n[DEBUG Sample] Ticker: {ticker}")
                print(f"   - Raw Closes (First 5): {raw_closes[:5]}")
                debug_printed = True

            # ë£¨í”„ ë²”ìœ„: ëì—ì„œ max_horizon ë§Œí¼ì€ ì •ë‹µì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ì œì™¸
            num_samples = len(sub_df) - self.lookback - max_horizon + 1
            if num_samples <= 0: continue

            for i in range(num_samples):
                window = values[i : i + self.lookback]
                curr_raw = raw_closes[i + self.lookback - 1]
                
                # [í•µì‹¬] 1, 3, 5, 7ì¼ ë’¤ ì •ë‹µì„ ëª¨ë‘ êµ¬í•´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦
                multi_labels = []
                
                for h in HORIZONS:
                    next_raw = raw_closes[i + self.lookback + h - 1]
                    threshold = 0.000
                    
                    if curr_raw == 0:
                        label = 0
                    else:
                        label = 1 if next_raw > curr_raw * (1 + threshold) else 0
                    multi_labels.append(label)
                
                # íšŒê·€ ë¼ë²¨ì€ ëŒ€í‘œê°’(ê°€ì¥ ë¨¼ 7ì¼) í•˜ë‚˜ë§Œ ì”€ (ì—¬ê¸°ì„  ë¶„ë¥˜ê°€ ë©”ì¸ì´ë¯€ë¡œ)
                label_reg = 0.0 
                
                X_ts_list.append(window)
                X_ticker_list.append(t_id)
                X_sector_list.append(s_id)
                y_class_list.append(multi_labels) # [0, 1, 1, 0] í˜•íƒœ ì €ì¥
                y_reg_list.append(label_reg)

        X_ts = np.array(X_ts_list)
        X_ticker = np.array(X_ticker_list)
        X_sector = np.array(X_sector_list)
        y_class = np.array(y_class_list) # Shape: (N, 4)
        y_reg = np.array(y_reg_list)
        
        info = {
            "n_tickers": len(self.ticker_to_id),
            "n_sectors": len(self.sector_to_id),
            "scaler": self.scaler,
            "n_features": len(available_cols),
            "horizons": HORIZONS # ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
        }
        
        return X_ts, X_ticker, X_sector, y_class, y_reg, info