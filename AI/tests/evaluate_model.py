# AI/tests/evaluate_model.py
"""
[ì‹œì¥ ì „ì²´ ì‹œê·¸ë„ íƒì§€ ë° í†µí•© ëª¨ë¸ ì„±ëŠ¥ í‰ê°€]
- S&P500 ì „ì²´ ë°ì´í„° ë“±ìœ¼ë¡œ í•™ìŠµëœ 'ë‹¨ì¼ ê¸€ë¡œë²Œ ëª¨ë¸'ì„ ë¡œë“œí•©ë‹ˆë‹¤.
- ëŒ€ìƒ ì¢…ëª©ë“¤ì˜ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë“œí•˜ì—¬, í•´ë‹¹ ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- ì‹œì¥ ì „ì²´ì—ì„œ ëª¨ë¸ì´ í¬ì°©í•œ ê¸°íšŒ(Signal)ë“¤ì˜ ì„±ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.
"""

import os
import sys
import joblib
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings
from tqdm import tqdm

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ê²½ë¡œ ë° ëª¨ë“ˆ ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../.."))
if project_root not in sys.path:
    sys.path.append(project_root)

from AI.modules.signal.models import get_model
from AI.modules.signal.core.data_loader import SignalDataLoader
from AI.modules.finder.selector import load_all_tickers_from_db

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  í‰ê°€ ì„¤ì • (CONFIG)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_TYPE = "transformer"
DATA_DIR = os.path.join(project_root, "AI", "data")

CONFIG = {
    "seq_len": 60,     # í•™ìŠµ ì‹œ ì„¤ì •í•œ Window Size
    "pred_h": 1,       # ì˜ˆì¸¡ ê¸°ê°„ (Next Day Return)
    "hold_thr": 0.003, # 0.3% ì´ìƒ ìƒìŠ¹ ê¸°ëŒ€ ì‹œ ë§¤ìˆ˜
    
    # ë‹¨ì¼ ê¸€ë¡œë²Œ ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ê²½ë¡œ
    "weights_path": os.path.join(DATA_DIR, "weights", "transformer", "universal_transformer.keras"), # íŒŒì¼ëª… í™•ì¸ í•„ìš”
    "scaler_path": os.path.join(DATA_DIR, "weights", "transformer", "universal_scaler.pkl"),
    
    # í‰ê°€ ê¸°ê°„
    "eval_start_date": "2025-01-01",
    "eval_end_date": "2025-10-20",
    
    # í‰ê°€ ëŒ€ìƒ: Noneì´ë©´ ì „ì²´, ë¦¬ìŠ¤íŠ¸ë©´ íŠ¹ì • ì¢…ëª©
    "test_tickers": ["AAPL", "TSLA", "MSFT", "NVDA", "GOOGL", "AMD"],
    
    "batch_size": 1024  # ëŒ€ëŸ‰ ì¶”ë¡ ì„ ìœ„í•´ ë°°ì¹˜ ì‚¬ì´ì¦ˆ í‚¤ì›€
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Helper Functions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _label_by_future_return(close_prices: pd.Series, horizon: int, threshold: float) -> pd.Series:
    """ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜ ë¼ë²¨ë§ (1: ìƒìŠ¹/BUY, 0: í•˜ë½/ë³´í•©)"""
    future_ret = (close_prices.shift(-horizon) / close_prices) - 1.0
    labels = np.where(future_ret > threshold, 1, 0)
    labels[-horizon:] = -1 
    return pd.Series(labels, index=close_prices.index), future_ret

def _build_sequences(df: pd.DataFrame, feature_cols: list, seq_len: int) -> np.ndarray:
    data = df[feature_cols].values
    num_samples = len(data) - seq_len + 1
    X = []
    for i in range(num_samples):
        X.append(data[i : i+seq_len])
    return np.array(X)

def _align_labels(target_series: pd.Series, seq_len: int) -> np.ndarray:
    return target_series.iloc[seq_len-1:].values

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  ë©”ì¸ í‰ê°€ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def evaluate_market_signals():
    print(f"\n[EVAL] ğŸš€ ê¸€ë¡œë²Œ ëª¨ë¸(Universal Model) ì„±ëŠ¥ í‰ê°€ ì‹œì‘")
    print(f"       ê¸°ê°„: {CONFIG['eval_start_date']} ~ {CONFIG['eval_end_date']}")
    
    # 1. í•„ìˆ˜ íŒŒì¼ í™•ì¸
    if not os.path.exists(CONFIG['weights_path']) or not os.path.exists(CONFIG['scaler_path']):
        print(f"[ERR] âŒ í•„ìˆ˜ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"      Weights: {CONFIG['weights_path']}")
        print(f"      Scaler : {CONFIG['scaler_path']}")
        print("      -> ì „ì²´ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¨ ê¸€ë¡œë²Œ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # 2. ê¸€ë¡œë²Œ ìì› ë¡œë“œ (ëª¨ë¸ & ìŠ¤ì¼€ì¼ëŸ¬)
    print("[EVAL] ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì¤‘...")
    try:
        # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        global_scaler = joblib.load(CONFIG['scaler_path'])
        
        # ëª¨ë¸ ë¡œë“œ (ConfigëŠ” ë¡œë“œ ì‹œ íŒŒì¼ì—ì„œ ë³µì›ë˜ë¯€ë¡œ ë¹ˆ dict)
        # ë‹¨, input_shape ë“± êµ¬ì¡° ìƒì„±ì„ ìœ„í•´ ê¸°ë³¸ê°’ì€ ë„£ì–´ì¤Œ
        model_wrapper = get_model(MODEL_TYPE, {
            "head_size": 256, "num_heads": 4, "ff_dim": 4, # ê¸°ë³¸ê°’ (í•„ìš”ì‹œ ìˆ˜ì •)
            "num_blocks": 4, "mlp_units": [128],
            "dropout": 0.1
        })
        model_wrapper.load(CONFIG['weights_path'])
        print("      âœ… ë¡œë“œ ì™„ë£Œ")
        
    except Exception as e:
        print(f"[ERR] ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 3. ëŒ€ìƒ ì¢…ëª© ì„ ì •
    if CONFIG['test_tickers']:
        tickers = CONFIG['test_tickers']
    else:
        print("[EVAL] DBì—ì„œ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì¤‘...")
        tickers = load_all_tickers_from_db(verbose=False)
    
    print(f"[EVAL] ë¶„ì„ ëŒ€ìƒ ì¢…ëª© ìˆ˜: {len(tickers)}ê°œ")

    # 4. ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„ ì„¤ì •
    fetch_start = pd.to_datetime(CONFIG['eval_start_date']) - pd.Timedelta(days=150)
    fetch_start_str = fetch_start.strftime("%Y-%m-%d")

    # ì¢…í•© ê²°ê³¼ ëˆ„ì ìš©
    global_y_true = []
    global_y_pred = []
    global_returns = []
    
    processed_count = 0

    # 5. ì¢…ëª©ë³„ ë°ì´í„° ë¡œë“œ ë° ì˜ˆì¸¡ (Loop)
    for ticker in tqdm(tickers, desc="ì‹œê·¸ë„ ìŠ¤ìº” ì¤‘"):
        try:
            # (1) ë°ì´í„° ë¡œë“œ (DB)
            loader = SignalDataLoader(sequence_length=CONFIG['seq_len'])
            loader.scaler = global_scaler # â˜… ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¼ëŸ¬ ì£¼ì…
            
            df = loader.load_data(ticker, fetch_start_str, CONFIG['eval_end_date'])
            
            if df.empty or len(df) < CONFIG['seq_len']:
                continue

            # âœ… [ìˆ˜ì •ëœ ë¶€ë¶„] ë‚ ì§œ ì»¬ëŸ¼ì„ ì¸ë±ìŠ¤ë¡œ ì„¤ì • (ì•ˆì „ì¥ì¹˜)
            # ------------------------------------------------------------------
            if 'date' in df.columns:
                df['date'] = pd.to_datetime(df['date'])  # datetime ë³€í™˜ ë³´ì¥
                df.set_index('date', inplace=True)       # ì¸ë±ìŠ¤ë¡œ ì„¤ì •
            elif not isinstance(df.index, pd.DatetimeIndex):
                # date ì»¬ëŸ¼ë„ ì—†ê³  ì¸ë±ìŠ¤ë„ ë‚ ì§œê°€ ì•„ë‹ˆë©´ ì²˜ë¦¬ ë¶ˆê°€
                print(f"[Skip] {ticker}: ë‚ ì§œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                continue
            # ------------------------------------------------------------------

            # (2) ì „ì²˜ë¦¬ ë° ì‹œí€€ìŠ¤ ìƒì„±
            # feature_cols ìƒì„± ì‹œ ì¸ë±ìŠ¤(ë‚ ì§œ)ëŠ” ìë™ìœ¼ë¡œ ì œì™¸ë¨ (np.numberë§Œ í¬í•¨í•˜ë¯€ë¡œ)
            feature_cols = df.select_dtypes(include=[np.number]).columns.tolist()
            
            # ë¼ë²¨ ë° ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
            labels, future_ret = _label_by_future_return(df["close"], CONFIG['pred_h'], CONFIG['hold_thr'])
            
            # ìœ íš¨ ë°ì´í„° ë§ˆìŠ¤í‚¹
            valid_mask = df[feature_cols].notna().all(axis=1) & (labels != -1) & future_ret.notna()
            df_valid = df[valid_mask]
            
            # í‰ê°€ ê¸°ê°„ í•„í„°ë§
            # âœ… ì´ì œ df_valid.indexê°€ DatetimeIndexì´ë¯€ë¡œ ì •ìƒ ì‘ë™í•¨
            dates_seq = pd.to_datetime(df_valid.index[CONFIG['seq_len']-1:])
            
            # Timezone ì •ë³´ê°€ ìˆë‹¤ë©´ ì œê±° (ë¹„êµë¥¼ ìœ„í•´)
            if dates_seq.tz is not None: 
                dates_seq = dates_seq.tz_localize(None)
            
            target_start = pd.to_datetime(CONFIG['eval_start_date'])
            target_end = pd.to_datetime(CONFIG['eval_end_date'])
            
            eval_mask = (dates_seq >= target_start) & (dates_seq <= target_end)
            
            if eval_mask.sum() == 0:
                continue

            # ë°ì´í„° ë³€í™˜ (transform only)
            # â˜… í•™ìŠµ ë•Œì™€ ë™ì¼í•œ Global Scalerë¥¼ ì‚¬ìš©í•˜ì—¬ transform í•´ì•¼ í•¨
            scaled_vals = loader.scaler.transform(df_valid[feature_cols])
            
            # DataFrame ì¬êµ¬ì„± (ì¸ë±ìŠ¤ ìœ ì§€)
            df_scaled = pd.DataFrame(scaled_vals, columns=feature_cols, index=df_valid.index)
            
            X_seq = _build_sequences(df_scaled, feature_cols, CONFIG['seq_len'])
            y_seq = _align_labels(labels[valid_mask], CONFIG['seq_len'])
            r_seq = _align_labels(future_ret[valid_mask], CONFIG['seq_len'])
            
            X_test = X_seq[eval_mask]
            y_test = y_seq[eval_mask]
            r_test = r_seq[eval_mask]
            
            if len(X_test) == 0: continue

            # (3) ëª¨ë¸ ì¶”ë¡  (Loaded Model ì‚¬ìš©)
            # verbose=0 ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ë£¨í”„ ë‚´ ë¡œê·¸ ìµœì†Œí™”
            y_probs = model_wrapper.predict(X_test) # (N, 1)
            y_pred_class = (y_probs > 0.5).astype(int).flatten()
            
            # (4) ê²°ê³¼ ëˆ„ì 
            global_y_true.extend(y_test)
            global_y_pred.extend(y_pred_class)
            global_returns.extend(r_test)
            
            processed_count += 1
            
        except Exception as e:
            # ë°ì´í„° ë¶ˆëŸ‰ ë“±ìœ¼ë¡œ ì¸í•œ ê°œë³„ ì¢…ëª© ì—ëŸ¬ëŠ” ë¬´ì‹œí•˜ê³  ì§„í–‰
            print(f"[Skip] {ticker}: {e}")
            pass

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    #  ì¢…í•© ê²°ê³¼ ë¦¬í¬íŠ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "="*60)
    print("ğŸ“¢ [MARKET-WIDE REPORT] ê¸€ë¡œë²Œ ëª¨ë¸ ì¢…í•© ì„±ëŠ¥ í‰ê°€")
    print("="*60)
    
    print(f"ë¶„ì„ ì™„ë£Œ ì¢…ëª© ìˆ˜ : {processed_count} / {len(tickers)}")
    
    if len(global_y_true) == 0:
        print("\n[ERR] ìœ íš¨í•œ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„ì´ë‚˜ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return

    # Numpy ë³€í™˜
    y_true = np.array(global_y_true)
    y_pred = np.array(global_y_pred)
    returns = np.array(global_returns)

    # 1. ë¶„ë¥˜ ì„±ëŠ¥
    acc = accuracy_score(y_true, y_pred)
    print(f"\n1ï¸âƒ£  ì˜ˆì¸¡ ì •í™•ë„ (Accuracy): {acc*100:.2f}%")
    print(classification_report(y_true, y_pred, target_names=["ê´€ë§(0)", "ë§¤ìˆ˜(1)"]))

    # 2. íˆ¬ì ì„±ê³¼ ë¶„ì„
    buy_mask = (y_pred == 1)
    n_buys = np.sum(buy_mask)
    
    print(f"\n2ï¸âƒ£  íˆ¬ì ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
    print(f"    - ì´ ìƒ˜í”Œ(ê±°ë˜ì¼) ìˆ˜ : {len(y_true)}")
    print(f"    - ë§¤ìˆ˜ ì‹œê·¸ë„ ë°œìƒ   : {n_buys}íšŒ (ë°œìƒë¥  {n_buys/len(y_true)*100:.1f}%)")
    
    if n_buys > 0:
        # ë§¤ìˆ˜ ì‹œê·¸ë„ ë°œìƒ ì‹œ ì‹¤ì œ ìˆ˜ìµë¥  ë¶„í¬
        buy_returns = returns[buy_mask]
        
        avg_return = np.mean(buy_returns)
        win_rate = np.mean(buy_returns > 0)
        
        # ì†ìµë¹„ ê³„ì‚°
        wins = buy_returns[buy_returns > 0]
        losses = buy_returns[buy_returns < 0]
        avg_win = np.mean(wins) if len(wins) > 0 else 0
        avg_loss = np.abs(np.mean(losses)) if len(losses) > 0 else 0
        profit_factor = avg_win / avg_loss if avg_loss > 0 else float('inf')

        print(f"    --------------------------------------------------")
        print(f"    â˜… ê¸°ëŒ€ ìˆ˜ìµë¥  (Avg Return) : {avg_return*100:.3f}%")
        print(f"    â˜… ì ì¤‘ë¥  (Win Rate)        : {win_rate*100:.2f}%")
        print(f"    â˜… ì†ìµë¹„ (Profit Factor)   : {profit_factor:.2f}")
        print(f"    --------------------------------------------------")
        
        # ë²¤ì¹˜ë§ˆí¬ ë¹„êµ
        market_avg = np.mean(returns)
        print(f"    (ì‹œì¥ í‰ê·  ìˆ˜ìµë¥ : {market_avg*100:.3f}%)")
        
        if avg_return > market_avg:
            print("    âœ… ëª¨ë¸ì´ ì‹œì¥ í‰ê· ì„ ìƒíšŒí–ˆìŠµë‹ˆë‹¤.")
        else:
            print("    âš ï¸ ëª¨ë¸ ì„±ê³¼ê°€ ì‹œì¥ í‰ê· ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤.")
    else:
        print("    [!] ë§¤ìˆ˜ ì‹œê·¸ë„ì´ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    evaluate_market_signals()